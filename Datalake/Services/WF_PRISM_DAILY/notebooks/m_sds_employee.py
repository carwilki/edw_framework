#Code converted on 2023-07-24 08:18:32
import os
import argparse
from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark.sql.window import Window
from pyspark.sql.types import *
from datetime import datetime
from Datalake.utils.genericUtilities import *
from Datalake.utils.configs import *
from Datalake.utils.mergeUtils import *
from Datalake.utils.logger import *
# COMMAND ----------

parser = argparse.ArgumentParser()
spark = SparkSession.getActiveSession()
parser.add_argument('env', type=str, help='Env Variable')
args = parser.parse_args()
env = args.env

if env is None or env == '':
    raise ValueError('env is not set')

refine = getEnvPrefix(env) + 'refine'
raw = getEnvPrefix(env) + 'raw'
legacy = getEnvPrefix(env) + 'legacy'


# COMMAND ----------
# Processing node SQ_Shortcut_to_SDS_EMPLOYEE_GROUP, type SOURCE 
# COLUMN COUNT: 3

SQ_Shortcut_to_SDS_EMPLOYEE_GROUP = spark.sql(f"""SELECT
SDS_EMPLOYEE_GROUP.SDS_EMPLOYEE_GROUP_ID,
SDS_EMPLOYEE_GROUP.SDS_EMPLOYEE_GROUP_GID,
SDS_EMPLOYEE_GROUP.SDS_EMPLOYEE_GROUP_NAME
FROM SDS_EMPLOYEE_GROUP""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node SQ_Shortcut_to_SDS_SERVICE_TERRITORY, type SOURCE 
# COLUMN COUNT: 2

SQ_Shortcut_to_SDS_SERVICE_TERRITORY = spark.sql(f"""SELECT
SDS_SERVICE_TERRITORY.SDS_SERVICE_TERRITORY_ID,
SDS_SERVICE_TERRITORY.STORE_NBR
FROM SDS_SERVICE_TERRITORY""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node SQ_Shortcut_to_SDS_USER, type SOURCE 
# COLUMN COUNT: 3

SQ_Shortcut_to_SDS_USER = spark.sql(f"""SELECT
SDS_USER.SDS_USER_ID,
SDS_USER.EMPLOYEE_ID,
SDS_USER.ASSOCIATE_DISPLAY_NAME
FROM SDS_USER""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT, type SOURCE 
# COLUMN COUNT: 6

SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT = spark.sql(f"""SELECT
EMPLOYEE_PROFILE_RPT.EMPLOYEE_ID,
EMPLOYEE_PROFILE_RPT.EMPL_FIRST_NAME,
EMPLOYEE_PROFILE_RPT.EMPL_LAST_NAME,
EMPLOYEE_PROFILE_RPT.EMPL_STATUS_CD,
EMPLOYEE_PROFILE_RPT.EMPL_STATUS_DESC,
EMPLOYEE_PROFILE_RPT.EMPL_TERM_DT
FROM EMPLOYEE_PROFILE_RPT""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node SQ_Shortcut_To_SITE_PROFILE, type SOURCE 
# COLUMN COUNT: 2

SQ_Shortcut_To_SITE_PROFILE = spark.sql(f"""SELECT
SITE_PROFILE.LOCATION_ID,
SITE_PROFILE.STORE_NBR
TINYINT""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node EXP_SDS_USER, type EXPRESSION 
# COLUMN COUNT: 3

# for each involved DataFrame, append the dataframe name to each column
SQ_Shortcut_to_SDS_USER_temp = SQ_Shortcut_to_SDS_USER.toDF(*["SQ_Shortcut_to_SDS_USER___" + col for col in SQ_Shortcut_to_SDS_USER.columns])

EXP_SDS_USER = SQ_Shortcut_to_SDS_USER_temp.selectExpr(
	"SQ_Shortcut_to_SDS_USER___sys_row_id as sys_row_id",
	"SQ_Shortcut_to_SDS_USER___SDS_USER_ID as SDS_USER_ID",
	"IF (LTRIM ( RTRIM ( SQ_Shortcut_to_SDS_USER___EMPLOYEE_ID ) ) IS NULL, NULL, cast(SQ_Shortcut_to_SDS_USER___EMPLOYEE_ID as int)) as o_EMPLOYEE_ID",
	"SQ_Shortcut_to_SDS_USER___ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME"
)

# COMMAND ----------
# Processing node SQ_Shortcut_to_SDS_SERVICE_RESOURCE, type SOURCE 
# COLUMN COUNT: 10

SQ_Shortcut_to_SDS_SERVICE_RESOURCE = spark.sql(f"""SELECT SDS_SERVICE_RESOURCE.SDS_SERVICE_RESOURCE_ID, 

SDS_SERVICE_RESOURCE.SDS_SERVICE_RESOURCE_NAME,

SDS_SERVICE_RESOURCE.EMPLOYEE_GROUP_NAME, 

SDS_SERVICE_RESOURCE.SDS_RELATED_RECORD_ID,

SDS_SERVICE_RESOURCE.BLOCK_1_APPOINTMENT_CAPACITY, 

SDS_SERVICE_RESOURCE.BLOCK_2_APPOINTMENT_CAPACITY, 

SDS_SERVICE_RESOURCE.MAX_CHECK_IN_PER_HOUR, 

SDS_SERVICE_RESOURCE.ACTIVE_FLAG ,

COALESCE(NEW_VALUE::Numeric(18,3), MAX_WEIGHT) AS MAX_WEIGHT,

 OLD_VALUE AS OLD_MAX_WEIGHT

FROM

 SDS_SERVICE_RESOURCE LEFT JOIN (SELECT SDS_SERVICE_RESOURCE_ID , SDS_FIELD_NAME, OLD_VALUE, NEW_VALUE, SDS_CREATED_TSTMP

FROM SDS_SERVICE_RESOURCE_HIST M WHERE  SDS_CREATED_TSTMP = (SELECT MAX( SDS_CREATED_TSTMP) FROM SDS_SERVICE_RESOURCE_HIST S 

WHERE S.SDS_SERVICE_RESOURCE_ID = M.SDS_SERVICE_RESOURCE_ID AND S.SDS_FIELD_NAME = 'PSVC_Max_Weight__c')

AND M.SDS_FIELD_NAME = 'PSVC_Max_Weight__c')  sh ON SDS_SERVICE_RESOURCE.SDS_SERVICE_RESOURCE_ID = sh.SDS_SERVICE_RESOURCE_ID""").withColumn("sys_row_id", monotonically_increasing_id())
# Conforming fields names to the component layout
SQ_Shortcut_to_SDS_SERVICE_RESOURCE = SQ_Shortcut_to_SDS_SERVICE_RESOURCE\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[0],'SDS_SERVICE_RESOURCE_ID')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[1],'SDS_SERVICE_RESOURCE_NAME')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[2],'EMPLOYEE_GROUP_NAME')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[3],'SDS_RELATED_RECORD_ID')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[4],'BLOCK_1_APPOINTMENT_CAPACITY')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[5],'BLOCK_2_APPOINTMENT_CAPACITY')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[6],'MAX_CHECK_IN_PER_HOUR')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[7],'ACTIVE_FLAG')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[8],'MAX_WEIGHT')\
	.withColumnRenamed(SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns[9],'OLD_MAX_WEIGHT')\

# COMMAND ----------
# Processing node SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER, type SOURCE 
# COLUMN COUNT: 2

SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER = spark.sql(f"""SELECT DISTINCT
SDS_SERVICE_TERRITORY_ID,
SDS_SERVICE_RESOURCE_ID
FROM {legacy}.SDS_SERVICE_TERRITORY_MEMBER""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node EXP_SERVICE_TERRITORY, type EXPRESSION 
# COLUMN COUNT: 2

# for each involved DataFrame, append the dataframe name to each column
SQ_Shortcut_to_SDS_SERVICE_TERRITORY_temp = SQ_Shortcut_to_SDS_SERVICE_TERRITORY.toDF(*["SQ_Shortcut_to_SDS_SERVICE_TERRITORY___" + col for col in SQ_Shortcut_to_SDS_SERVICE_TERRITORY.columns])

EXP_SERVICE_TERRITORY = SQ_Shortcut_to_SDS_SERVICE_TERRITORY_temp.selectExpr(
	"SQ_Shortcut_to_SDS_SERVICE_TERRITORY___sys_row_id as sys_row_id",
	"SQ_Shortcut_to_SDS_SERVICE_TERRITORY___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"cast(SQ_Shortcut_to_SDS_SERVICE_TERRITORY___STORE_NBR as int) as o_STORE_NBR"
)

# COMMAND ----------
# Processing node SQ_Shortcut_to_SDS_EMPLOYEE, type SOURCE 
# COLUMN COUNT: 20

SQ_Shortcut_to_SDS_EMPLOYEE = spark.sql(f"""SELECT
SDS_EMPLOYEE_ID,
SDS_LOCATION_ID,
LOCATION_ID,
SDS_USER_ID,
EMPLOYEE_ID,
SDS_EMPLOYEE_GROUP_GID,
SDS_EMPLOYEE_GROUP_NAME,
SDS_EMPLOYEE_DISPLAY_NAME,
EMPLOYEE_FIRST_NAME,
EMPLOYEE_LAST_NAME,
EMPLOYEE_STATUS_CD,
EMPLOYEE_STATUS_DESC,
MAX_BLOCK_1_CAPACITY,
MAX_BLOCK_2_CAPACITY,
MAX_CHECK_IN_PER_HOUR,
EMPLOYEE_TERM_DT,
LOAD_TSTMP,
SDS_EMPLOYEE_ACTIVE_FLAG,
MAX_WEIGHT,
OLD_MAX_WEIGHT
FROM {legacy}.SDS_EMPLOYEE""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMA.ND ----------
# Processing node JNR_SDS_SERVICE_RESOURCE, type JOINER . Note: using additional SELECT to rename incoming columns
# COLUMN COUNT: 12

# for each involved DataFrame, append the dataframe name to each column
SQ_Shortcut_to_SDS_SERVICE_RESOURCE_temp = SQ_Shortcut_to_SDS_SERVICE_RESOURCE.toDF(*["SQ_Shortcut_to_SDS_SERVICE_RESOURCE___" + col for col in SQ_Shortcut_to_SDS_SERVICE_RESOURCE.columns])
SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER_temp = SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER.toDF(*["SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER___" + col for col in SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER.columns])

JNR_SDS_SERVICE_RESOURCE = SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER_temp.join(SQ_Shortcut_to_SDS_SERVICE_RESOURCE_temp,[SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER_temp.SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER___SDS_SERVICE_RESOURCE_ID == SQ_Shortcut_to_SDS_SERVICE_RESOURCE_temp.SQ_Shortcut_to_SDS_SERVICE_RESOURCE___SDS_SERVICE_RESOURCE_ID],'inner').selectExpr(
	"SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"SQ_Shortcut_to_SDS_SERVICE_TERRITORY_MEMBER___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___SDS_SERVICE_RESOURCE_ID as i_SDS_SERVICE_RESOURCE_ID",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___SDS_SERVICE_RESOURCE_NAME as i_SDS_SERVICE_RESOURCE_NAME",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___EMPLOYEE_GROUP_NAME as i_EMPLOYEE_GROUP_NAME",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___SDS_RELATED_RECORD_ID as i_SDS_RELATED_RECORD_ID",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___BLOCK_1_APPOINTMENT_CAPACITY as i_BLOCK_1_APPOINTMENT_CAPACITY",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___BLOCK_2_APPOINTMENT_CAPACITY as i_BLOCK_2_APPOINTMENT_CAPACITY",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___MAX_CHECK_IN_PER_HOUR as i_MAX_CHECK_IN_PER_HOUR",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___ACTIVE_FLAG as ACTIVE_FLAG",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___MAX_WEIGHT as MAX_WEIGHT",
	"SQ_Shortcut_to_SDS_SERVICE_RESOURCE___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT")

# COMMAND ----------
# Processing node JNR_SDS_USER, type JOINER . Note: using additional SELECT to rename incoming columns
# COLUMN COUNT: 14

# for each involved DataFrame, append the dataframe name to each column
EXP_SDS_USER_temp = EXP_SDS_USER.toDF(*["EXP_SDS_USER___" + col for col in EXP_SDS_USER.columns])
JNR_SDS_SERVICE_RESOURCE_temp = JNR_SDS_SERVICE_RESOURCE.toDF(*["JNR_SDS_SERVICE_RESOURCE___" + col for col in JNR_SDS_SERVICE_RESOURCE.columns])

JNR_SDS_USER = JNR_SDS_SERVICE_RESOURCE_temp.join(EXP_SDS_USER_temp,[JNR_SDS_SERVICE_RESOURCE_temp.JNR_SDS_SERVICE_RESOURCE___i_SDS_RELATED_RECORD_ID == EXP_SDS_USER_temp.EXP_SDS_USER___SDS_USER_ID],'left_outer').selectExpr(
	"JNR_SDS_SERVICE_RESOURCE___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"JNR_SDS_SERVICE_RESOURCE___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"JNR_SDS_SERVICE_RESOURCE___i_SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"JNR_SDS_SERVICE_RESOURCE___i_EMPLOYEE_GROUP_NAME as EMPLOYEE_GROUP_NAME",
	"JNR_SDS_SERVICE_RESOURCE___i_SDS_RELATED_RECORD_ID as SDS_RELATED_RECORD_ID",
	"JNR_SDS_SERVICE_RESOURCE___i_BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"JNR_SDS_SERVICE_RESOURCE___i_BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"JNR_SDS_SERVICE_RESOURCE___i_MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"JNR_SDS_SERVICE_RESOURCE___ACTIVE_FLAG as ACTIVE_FLAG",
	"EXP_SDS_USER___SDS_USER_ID as i_SDS_USER_ID",
	"EXP_SDS_USER___o_EMPLOYEE_ID as i_EMPLOYEE_ID",
	"EXP_SDS_USER___ASSOCIATE_DISPLAY_NAME as i_ASSOCIATE_DISPLAY_NAME",
	"JNR_SDS_SERVICE_RESOURCE___MAX_WEIGHT as MAX_WEIGHT",
	"JNR_SDS_SERVICE_RESOURCE___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT")

# COMMAND ----------
# Processing node JNR_SDS_SERVICE_TERRITORY, type JOINER . Note: using additional SELECT to rename incoming columns
# COLUMN COUNT: 15

# for each involved DataFrame, append the dataframe name to each column
JNR_SDS_USER_temp = JNR_SDS_USER.toDF(*["JNR_SDS_USER___" + col for col in JNR_SDS_USER.columns])
EXP_SERVICE_TERRITORY_temp = EXP_SERVICE_TERRITORY.toDF(*["EXP_SERVICE_TERRITORY___" + col for col in EXP_SERVICE_TERRITORY.columns])

JNR_SDS_SERVICE_TERRITORY = JNR_SDS_USER_temp.join(EXP_SERVICE_TERRITORY_temp,[JNR_SDS_USER_temp.JNR_SDS_USER___SDS_SERVICE_TERRITORY_ID == EXP_SERVICE_TERRITORY_temp.EXP_SERVICE_TERRITORY___SDS_SERVICE_TERRITORY_ID],'left_outer').selectExpr(
	"JNR_SDS_USER___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"JNR_SDS_USER___SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"JNR_SDS_USER___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"JNR_SDS_USER___EMPLOYEE_GROUP_NAME as EMPLOYEE_GROUP_NAME",
	"JNR_SDS_USER___i_SDS_USER_ID as SDS_USER_ID",
	"JNR_SDS_USER___i_EMPLOYEE_ID as EMPLOYEE_ID",
	"JNR_SDS_USER___i_ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME",
	"JNR_SDS_USER___BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"JNR_SDS_USER___BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"JNR_SDS_USER___MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"JNR_SDS_USER___ACTIVE_FLAG as ACTIVE_FLAG",
	"EXP_SERVICE_TERRITORY___SDS_SERVICE_TERRITORY_ID as i_SDS_SERVICE_TERRITORY_ID",
	"EXP_SERVICE_TERRITORY___o_STORE_NBR as i_STORE_NBR",
	"JNR_SDS_USER___MAX_WEIGHT as MAX_WEIGHT",
	"JNR_SDS_USER___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT")

# COMMAND ----------
# Processing node JNR_SITE_PROFILE, type JOINER . Note: using additional SELECT to rename incoming columns
# COLUMN COUNT: 16

# for each involved DataFrame, append the dataframe name to each column
JNR_SDS_SERVICE_TERRITORY_temp = JNR_SDS_SERVICE_TERRITORY.toDF(*["JNR_SDS_SERVICE_TERRITORY___" + col for col in JNR_SDS_SERVICE_TERRITORY.columns])
SQ_Shortcut_To_SITE_PROFILE_temp = SQ_Shortcut_To_SITE_PROFILE.toDF(*["SQ_Shortcut_To_SITE_PROFILE___" + col for col in SQ_Shortcut_To_SITE_PROFILE.columns])

JNR_SITE_PROFILE = SQ_Shortcut_To_SITE_PROFILE_temp.join(JNR_SDS_SERVICE_TERRITORY_temp,[SQ_Shortcut_To_SITE_PROFILE_temp.SQ_Shortcut_To_SITE_PROFILE___STORE_NBR == JNR_SDS_SERVICE_TERRITORY_temp.JNR_SDS_SERVICE_TERRITORY___i_STORE_NBR],'inner').selectExpr(
	"JNR_SDS_SERVICE_TERRITORY___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"JNR_SDS_SERVICE_TERRITORY___SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"JNR_SDS_SERVICE_TERRITORY___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"JNR_SDS_SERVICE_TERRITORY___EMPLOYEE_GROUP_NAME as EMPLOYEE_GROUP_NAME",
	"JNR_SDS_SERVICE_TERRITORY___SDS_USER_ID as SDS_USER_ID",
	"JNR_SDS_SERVICE_TERRITORY___EMPLOYEE_ID as EMPLOYEE_ID",
	"JNR_SDS_SERVICE_TERRITORY___ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME",
	"JNR_SDS_SERVICE_TERRITORY___BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"JNR_SDS_SERVICE_TERRITORY___BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"JNR_SDS_SERVICE_TERRITORY___MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"JNR_SDS_SERVICE_TERRITORY___i_STORE_NBR as STORE_NBR",
	"JNR_SDS_SERVICE_TERRITORY___ACTIVE_FLAG as ACTIVE_FLAG",
	"SQ_Shortcut_To_SITE_PROFILE___LOCATION_ID as i_LOCATION_ID",
	"SQ_Shortcut_To_SITE_PROFILE___STORE_NBR as i_STORE_NBR",
	"JNR_SDS_SERVICE_TERRITORY___MAX_WEIGHT as MAX_WEIGHT",
	"JNR_SDS_SERVICE_TERRITORY___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT")

# COMMAND ----------
# Processing node JNR_EMPLOYEE_PROFILE_RPT, type JOINER . Note: using additional SELECT to rename incoming columns
# COLUMN COUNT: 20

# for each involved DataFrame, append the dataframe name to each column
JNR_SITE_PROFILE_temp = JNR_SITE_PROFILE.toDF(*["JNR_SITE_PROFILE___" + col for col in JNR_SITE_PROFILE.columns])
SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT_temp = SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT.toDF(*["SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT___" + col for col in SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT.columns])

JNR_EMPLOYEE_PROFILE_RPT = JNR_SITE_PROFILE_temp.join(SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT_temp,[JNR_SITE_PROFILE_temp.JNR_SITE_PROFILE___EMPLOYEE_ID == SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT_temp.SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT___EMPLOYEE_ID],'left_outer').selectExpr(
	"JNR_SITE_PROFILE___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"JNR_SITE_PROFILE___SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"JNR_SITE_PROFILE___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"JNR_SITE_PROFILE___EMPLOYEE_GROUP_NAME as EMPLOYEE_GROUP_NAME",
	"JNR_SITE_PROFILE___SDS_USER_ID as SDS_USER_ID",
	"JNR_SITE_PROFILE___EMPLOYEE_ID as EMPLOYEE_ID",
	"JNR_SITE_PROFILE___ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME",
	"JNR_SITE_PROFILE___i_LOCATION_ID as LOCATION_ID",
	"JNR_SITE_PROFILE___BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"JNR_SITE_PROFILE___BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"JNR_SITE_PROFILE___MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"JNR_SITE_PROFILE___ACTIVE_FLAG as ACTIVE_FLAG",
	"SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT___EMPLOYEE_ID as i_EMPLOYEE_ID",
	"SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT___EMPL_FIRST_NAME as i_EMPL_FIRST_NAME",
	"SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT___EMPL_LAST_NAME as i_EMPL_LAST_NAME",
	"SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT___EMPL_STATUS_CD as i_EMPL_STATUS_CD",
	"SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT___EMPL_STATUS_DESC as i_EMPL_STATUS_DESC",
	"SQ_Shortcut_to_EMPLOYEE_PROFILE_RPT___EMPL_TERM_DT as i_EMPL_TERM_DT",
	"JNR_SITE_PROFILE___MAX_WEIGHT as MAX_WEIGHT",
	"JNR_SITE_PROFILE___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT")

# COMMAND ----------
# Processing node JNR_SDS_EMPLOYEE_GROUP, type JOINER . Note: using additional SELECT to rename incoming columns
# COLUMN COUNT: 23

# for each involved DataFrame, append the dataframe name to each column
JNR_EMPLOYEE_PROFILE_RPT_temp = JNR_EMPLOYEE_PROFILE_RPT.toDF(*["JNR_EMPLOYEE_PROFILE_RPT___" + col for col in JNR_EMPLOYEE_PROFILE_RPT.columns])
SQ_Shortcut_to_SDS_EMPLOYEE_GROUP_temp = SQ_Shortcut_to_SDS_EMPLOYEE_GROUP.toDF(*["SQ_Shortcut_to_SDS_EMPLOYEE_GROUP___" + col for col in SQ_Shortcut_to_SDS_EMPLOYEE_GROUP.columns])

JNR_SDS_EMPLOYEE_GROUP = SQ_Shortcut_to_SDS_EMPLOYEE_GROUP_temp.join(JNR_EMPLOYEE_PROFILE_RPT_temp,[SQ_Shortcut_to_SDS_EMPLOYEE_GROUP_temp.SQ_Shortcut_to_SDS_EMPLOYEE_GROUP___SDS_EMPLOYEE_GROUP_ID == JNR_EMPLOYEE_PROFILE_RPT_temp.JNR_EMPLOYEE_PROFILE_RPT___EMPLOYEE_GROUP_NAME],'right_outer').selectExpr(
	"JNR_EMPLOYEE_PROFILE_RPT___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"JNR_EMPLOYEE_PROFILE_RPT___SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"JNR_EMPLOYEE_PROFILE_RPT___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"JNR_EMPLOYEE_PROFILE_RPT___EMPLOYEE_GROUP_NAME as EMPLOYEE_GROUP_NAME",
	"JNR_EMPLOYEE_PROFILE_RPT___SDS_USER_ID as SDS_USER_ID",
	"JNR_EMPLOYEE_PROFILE_RPT___BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"JNR_EMPLOYEE_PROFILE_RPT___BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"JNR_EMPLOYEE_PROFILE_RPT___MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"JNR_EMPLOYEE_PROFILE_RPT___EMPLOYEE_ID as EMPLOYEE_ID",
	"JNR_EMPLOYEE_PROFILE_RPT___ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME",
	"JNR_EMPLOYEE_PROFILE_RPT___LOCATION_ID as LOCATION_ID",
	"JNR_EMPLOYEE_PROFILE_RPT___i_EMPL_FIRST_NAME as i_EMPL_FIRST_NAME",
	"JNR_EMPLOYEE_PROFILE_RPT___i_EMPL_LAST_NAME as i_EMPL_LAST_NAME",
	"JNR_EMPLOYEE_PROFILE_RPT___i_EMPL_STATUS_CD as i_EMPL_STATUS_CD",
	"JNR_EMPLOYEE_PROFILE_RPT___i_EMPL_STATUS_DESC as i_EMPL_STATUS_DESC",
	"JNR_EMPLOYEE_PROFILE_RPT___i_EMPL_TERM_DT as i_EMPL_TERM_DT",
	"JNR_EMPLOYEE_PROFILE_RPT___ACTIVE_FLAG as ACTIVE_FLAG",
	"SQ_Shortcut_to_SDS_EMPLOYEE_GROUP___SDS_EMPLOYEE_GROUP_ID as SDS_EMPLOYEE_GROUP_ID",
	"SQ_Shortcut_to_SDS_EMPLOYEE_GROUP___SDS_EMPLOYEE_GROUP_GID as SDS_EMPLOYEE_GROUP_GID",
	"SQ_Shortcut_to_SDS_EMPLOYEE_GROUP___SDS_EMPLOYEE_GROUP_NAME as SDS_EMPLOYEE_GROUP_NAME",
	"JNR_EMPLOYEE_PROFILE_RPT___MAX_WEIGHT as MAX_WEIGHT",
	"JNR_EMPLOYEE_PROFILE_RPT___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT")\
	.withColumn('i_EMPLOYEE_ID', lit(None))
	

# COMMAND ----------
# Processing node JNR_SDS_EMPLOYEE, type JOINER . Note: using additional SELECT to rename incoming columns
# COLUMN COUNT: 40

# for each involved DataFrame, append the dataframe name to each column
SQ_Shortcut_to_SDS_EMPLOYEE_temp = SQ_Shortcut_to_SDS_EMPLOYEE.toDF(*["SQ_Shortcut_to_SDS_EMPLOYEE___" + col for col in SQ_Shortcut_to_SDS_EMPLOYEE.columns])
JNR_SDS_EMPLOYEE_GROUP_temp = JNR_SDS_EMPLOYEE_GROUP.toDF(*["JNR_SDS_EMPLOYEE_GROUP___" + col for col in JNR_SDS_EMPLOYEE_GROUP.columns])

JNR_SDS_EMPLOYEE = JNR_SDS_EMPLOYEE_GROUP_temp.join(SQ_Shortcut_to_SDS_EMPLOYEE_temp,[JNR_SDS_EMPLOYEE_GROUP_temp.JNR_SDS_EMPLOYEE_GROUP___SDS_SERVICE_RESOURCE_ID == SQ_Shortcut_to_SDS_EMPLOYEE_temp.SQ_Shortcut_to_SDS_EMPLOYEE___SDS_EMPLOYEE_ID, JNR_SDS_EMPLOYEE_GROUP_temp.JNR_SDS_EMPLOYEE_GROUP___SDS_SERVICE_TERRITORY_ID == SQ_Shortcut_to_SDS_EMPLOYEE_temp.SQ_Shortcut_to_SDS_EMPLOYEE___SDS_LOCATION_ID],'left_outer').selectExpr(
	"JNR_SDS_EMPLOYEE_GROUP___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"JNR_SDS_EMPLOYEE_GROUP___SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"JNR_SDS_EMPLOYEE_GROUP___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"JNR_SDS_EMPLOYEE_GROUP___SDS_USER_ID as SDS_USER_ID",
	"JNR_SDS_EMPLOYEE_GROUP___EMPLOYEE_ID as EMPLOYEE_ID",
	"JNR_SDS_EMPLOYEE_GROUP___ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME",
	"JNR_SDS_EMPLOYEE_GROUP___LOCATION_ID as LOCATION_ID",
	"JNR_SDS_EMPLOYEE_GROUP___i_EMPL_FIRST_NAME as EMPL_FIRST_NAME",
	"JNR_SDS_EMPLOYEE_GROUP___i_EMPL_LAST_NAME as EMPL_LAST_NAME",
	"JNR_SDS_EMPLOYEE_GROUP___i_EMPL_STATUS_CD as EMPL_STATUS_CD",
	"JNR_SDS_EMPLOYEE_GROUP___i_EMPL_STATUS_DESC as EMPL_STATUS_DESC",
	"JNR_SDS_EMPLOYEE_GROUP___BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"JNR_SDS_EMPLOYEE_GROUP___BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"JNR_SDS_EMPLOYEE_GROUP___MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"JNR_SDS_EMPLOYEE_GROUP___i_EMPL_TERM_DT as EMPL_TERM_DT",
	"JNR_SDS_EMPLOYEE_GROUP___SDS_EMPLOYEE_GROUP_GID as SDS_EMPLOYEE_GROUP_GID",
	"JNR_SDS_EMPLOYEE_GROUP___SDS_EMPLOYEE_GROUP_NAME as SDS_EMPLOYEE_GROUP_NAME",
	"JNR_SDS_EMPLOYEE_GROUP___ACTIVE_FLAG as ACTIVE_FLAG",
	"SQ_Shortcut_to_SDS_EMPLOYEE___SDS_EMPLOYEE_ID as i_SDS_EMPLOYEE_ID",
	"SQ_Shortcut_to_SDS_EMPLOYEE___SDS_LOCATION_ID as i_SDS_LOCATION_ID",
	"SQ_Shortcut_to_SDS_EMPLOYEE___LOCATION_ID as i_LOCATION_ID",
	"SQ_Shortcut_to_SDS_EMPLOYEE___SDS_USER_ID as i_SDS_USER_ID",
	"SQ_Shortcut_to_SDS_EMPLOYEE___EMPLOYEE_ID as i_EMPLOYEE_ID",
	"SQ_Shortcut_to_SDS_EMPLOYEE___SDS_EMPLOYEE_GROUP_GID as i_SDS_EMPLOYEE_GROUP_GID",
	"SQ_Shortcut_to_SDS_EMPLOYEE___SDS_EMPLOYEE_GROUP_NAME as i_SDS_EMPLOYEE_GROUP_NAME",
	"SQ_Shortcut_to_SDS_EMPLOYEE___SDS_EMPLOYEE_DISPLAY_NAME as i_SDS_EMPLOYEE_DISPLAY_NAME",
	"SQ_Shortcut_to_SDS_EMPLOYEE___EMPLOYEE_FIRST_NAME as i_EMPLOYEE_FIRST_NAME",
	"SQ_Shortcut_to_SDS_EMPLOYEE___EMPLOYEE_LAST_NAME as i_EMPLOYEE_LAST_NAME",
	"SQ_Shortcut_to_SDS_EMPLOYEE___EMPLOYEE_STATUS_CD as i_EMPLOYEE_STATUS_CD",
	"SQ_Shortcut_to_SDS_EMPLOYEE___EMPLOYEE_STATUS_DESC as i_EMPLOYEE_STATUS_DESC",
	"SQ_Shortcut_to_SDS_EMPLOYEE___MAX_BLOCK_1_CAPACITY as i_MAX_BLOCK_1_CAPACITY",
	"SQ_Shortcut_to_SDS_EMPLOYEE___MAX_BLOCK_2_CAPACITY as i_MAX_BLOCK_2_CAPACITY",
	"SQ_Shortcut_to_SDS_EMPLOYEE___MAX_CHECK_IN_PER_HOUR as i_MAX_CHECK_IN_PER_HOUR",
	"SQ_Shortcut_to_SDS_EMPLOYEE___EMPLOYEE_TERM_DT as i_EMPLOYEE_TERM_DT",
	"SQ_Shortcut_to_SDS_EMPLOYEE___LOAD_TSTMP as i_LOAD_TSTMP",
	"SQ_Shortcut_to_SDS_EMPLOYEE___SDS_EMPLOYEE_ACTIVE_FLAG as i_SDS_EMPLOYEE_ACTIVE_FLAG",
	"JNR_SDS_EMPLOYEE_GROUP___MAX_WEIGHT as MAX_WEIGHT",
	"JNR_SDS_EMPLOYEE_GROUP___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT",
	"SQ_Shortcut_to_SDS_EMPLOYEE___MAX_WEIGHT as i_MAX_WEIGHT",
	"SQ_Shortcut_to_SDS_EMPLOYEE___OLD_MAX_WEIGHT as i_OLD_MAX_WEIGHT")

# COMMAND ----------
# Processing node FIL_SDS_EMPLOYEE, type FILTER 
# COLUMN COUNT: 40

# for each involved DataFrame, append the dataframe name to each column
JNR_SDS_EMPLOYEE_temp = JNR_SDS_EMPLOYEE.toDF(*["JNR_SDS_EMPLOYEE___" + col for col in JNR_SDS_EMPLOYEE.columns])

FIL_SDS_EMPLOYEE = JNR_SDS_EMPLOYEE_temp.selectExpr(
	"JNR_SDS_EMPLOYEE___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"JNR_SDS_EMPLOYEE___SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"JNR_SDS_EMPLOYEE___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"JNR_SDS_EMPLOYEE___SDS_USER_ID as SDS_USER_ID",
	"JNR_SDS_EMPLOYEE___EMPLOYEE_ID as EMPLOYEE_ID",
	"JNR_SDS_EMPLOYEE___ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME",
	"JNR_SDS_EMPLOYEE___LOCATION_ID as LOCATION_ID",
	"JNR_SDS_EMPLOYEE___EMPL_FIRST_NAME as EMPL_FIRST_NAME",
	"JNR_SDS_EMPLOYEE___EMPL_LAST_NAME as EMPL_LAST_NAME",
	"JNR_SDS_EMPLOYEE___EMPL_STATUS_CD as EMPL_STATUS_CD",
	"JNR_SDS_EMPLOYEE___EMPL_STATUS_DESC as EMPL_STATUS_DESC",
	"JNR_SDS_EMPLOYEE___BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"JNR_SDS_EMPLOYEE___BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"JNR_SDS_EMPLOYEE___MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"JNR_SDS_EMPLOYEE___EMPL_TERM_DT as EMPL_TERM_DT",
	"JNR_SDS_EMPLOYEE___SDS_EMPLOYEE_GROUP_GID as SDS_EMPLOYEE_GROUP_GID",
	"JNR_SDS_EMPLOYEE___SDS_EMPLOYEE_GROUP_NAME as SDS_EMPLOYEE_GROUP_NAME",
	"JNR_SDS_EMPLOYEE___ACTIVE_FLAG as ACTIVE_FLAG",
	"JNR_SDS_EMPLOYEE___i_SDS_EMPLOYEE_ID as i_SDS_EMPLOYEE_ID",
	"JNR_SDS_EMPLOYEE___i_SDS_LOCATION_ID as i_SDS_LOCATION_ID",
	"JNR_SDS_EMPLOYEE___i_LOCATION_ID as i_LOCATION_ID",
	"JNR_SDS_EMPLOYEE___i_SDS_USER_ID as i_SDS_USER_ID",
	"JNR_SDS_EMPLOYEE___i_EMPLOYEE_ID as i_EMPLOYEE_ID",
	"JNR_SDS_EMPLOYEE___i_SDS_EMPLOYEE_GROUP_GID as i_SDS_EMPLOYEE_GROUP_GID",
	"JNR_SDS_EMPLOYEE___i_SDS_EMPLOYEE_GROUP_NAME as i_SDS_EMPLOYEE_GROUP_NAME",
	"JNR_SDS_EMPLOYEE___i_SDS_EMPLOYEE_DISPLAY_NAME as i_SDS_EMPLOYEE_DISPLAY_NAME",
	"JNR_SDS_EMPLOYEE___i_EMPLOYEE_FIRST_NAME as i_EMPLOYEE_FIRST_NAME",
	"JNR_SDS_EMPLOYEE___i_EMPLOYEE_LAST_NAME as i_EMPLOYEE_LAST_NAME",
	"JNR_SDS_EMPLOYEE___i_EMPLOYEE_STATUS_CD as i_EMPLOYEE_STATUS_CD",
	"JNR_SDS_EMPLOYEE___i_EMPLOYEE_STATUS_DESC as i_EMPLOYEE_STATUS_DESC",
	"JNR_SDS_EMPLOYEE___i_MAX_BLOCK_1_CAPACITY as i_MAX_BLOCK_1_CAPACITY",
	"JNR_SDS_EMPLOYEE___i_MAX_BLOCK_2_CAPACITY as i_MAX_BLOCK_2_CAPACITY",
	"JNR_SDS_EMPLOYEE___i_MAX_CHECK_IN_PER_HOUR as i_MAX_CHECK_IN_PER_HOUR",
	"JNR_SDS_EMPLOYEE___i_EMPLOYEE_TERM_DT as i_EMPLOYEE_TERM_DT",
	"JNR_SDS_EMPLOYEE___i_LOAD_TSTMP as i_LOAD_TSTMP",
	"JNR_SDS_EMPLOYEE___i_SDS_EMPLOYEE_ACTIVE_FLAG as i_SDS_EMPLOYEE_ACTIVE_FLAG",
	"JNR_SDS_EMPLOYEE___MAX_WEIGHT as MAX_WEIGHT",
	"JNR_SDS_EMPLOYEE___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT",
	"JNR_SDS_EMPLOYEE___i_MAX_WEIGHT as i_MAX_WEIGHT",
	"JNR_SDS_EMPLOYEE___i_OLD_MAX_WEIGHT as i_OLD_MAX_WEIGHT").filter("i_SDS_EMPLOYEE_ID IS NULL OR i_SDS_EMPLOYEE_ID IS NOT NULL AND ( IF (ASSOCIATE_DISPLAY_NAME IS NULL, ' ', ASSOCIATE_DISPLAY_NAME) != IF (i_SDS_EMPLOYEE_DISPLAY_NAME IS NULL, ' ', i_SDS_EMPLOYEE_DISPLAY_NAME) OR IF (LOCATION_ID IS NULL, - 99999, LOCATION_ID) != IF (i_LOCATION_ID IS NULL, - 99999, i_LOCATION_ID) OR IF (SDS_USER_ID IS NULL, ' ', SDS_USER_ID) != IF (i_SDS_USER_ID IS NULL, ' ', i_SDS_USER_ID) OR IF (EMPLOYEE_ID IS NULL, - 99999, EMPLOYEE_ID) != IF (i_EMPLOYEE_ID IS NULL, - 99999, i_EMPLOYEE_ID) OR IF (SDS_EMPLOYEE_GROUP_GID IS NULL, - 99999, SDS_EMPLOYEE_GROUP_GID) != IF (i_SDS_EMPLOYEE_GROUP_GID IS NULL, - 99999, i_SDS_EMPLOYEE_GROUP_GID) OR IF (SDS_EMPLOYEE_GROUP_NAME IS NULL, ' ', SDS_EMPLOYEE_GROUP_NAME) != IF (i_SDS_EMPLOYEE_GROUP_NAME IS NULL, ' ', i_SDS_EMPLOYEE_GROUP_NAME) OR IF (EMPL_FIRST_NAME IS NULL, ' ', EMPL_FIRST_NAME) != IF (i_EMPLOYEE_FIRST_NAME IS NULL, ' ', i_EMPLOYEE_FIRST_NAME) OR IF (EMPL_LAST_NAME IS NULL, ' ', EMPL_LAST_NAME) != IF (i_EMPLOYEE_LAST_NAME IS NULL, ' ', i_EMPLOYEE_LAST_NAME) OR IF (EMPL_STATUS_CD IS NULL, ' ', EMPL_STATUS_CD) != IF (i_EMPLOYEE_STATUS_CD IS NULL, ' ', i_EMPLOYEE_STATUS_CD) OR IF (EMPL_STATUS_DESC IS NULL, ' ', EMPL_STATUS_DESC) != IF (i_EMPLOYEE_STATUS_DESC IS NULL, ' ', i_EMPLOYEE_STATUS_DESC) OR IF (EMPL_TERM_DT IS NULL, TO_DATE ( '1901-01-01' , 'YYYY-MM-DD' ), EMPL_TERM_DT) != IF (i_EMPLOYEE_TERM_DT IS NULL, TO_DATE ( '1901-01-01' , 'YYYY-MM-DD' ), i_EMPLOYEE_TERM_DT) OR IF (BLOCK_1_APPOINTMENT_CAPACITY IS NULL, - 99999, BLOCK_1_APPOINTMENT_CAPACITY) != IF (i_MAX_BLOCK_1_CAPACITY IS NULL, - 99999, i_MAX_BLOCK_1_CAPACITY) OR IF (BLOCK_2_APPOINTMENT_CAPACITY IS NULL, - 99999, BLOCK_2_APPOINTMENT_CAPACITY) != IF (i_MAX_BLOCK_2_CAPACITY IS NULL, - 99999, i_MAX_BLOCK_2_CAPACITY) OR IF (MAX_CHECK_IN_PER_HOUR IS NULL, - 99999, MAX_CHECK_IN_PER_HOUR) != IF (i_MAX_CHECK_IN_PER_HOUR IS NULL, - 99999, i_MAX_CHECK_IN_PER_HOUR) OR IF (ACTIVE_FLAG IS NULL, - 99999, ACTIVE_FLAG) != IF (i_SDS_EMPLOYEE_ACTIVE_FLAG IS NULL, - 99999, i_SDS_EMPLOYEE_ACTIVE_FLAG) OR IF (OLD_MAX_WEIGHT IS NULL, - 99999, OLD_MAX_WEIGHT) != IF (i_OLD_MAX_WEIGHT IS NULL, - 99999, i_OLD_MAX_WEIGHT) OR IF (MAX_WEIGHT IS NULL, - 99999, MAX_WEIGHT) != IF (i_MAX_WEIGHT IS NULL, - 99999, i_MAX_WEIGHT) )").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node EXP_SDS_EMPLOYEE, type EXPRESSION 
# COLUMN COUNT: 36

# for each involved DataFrame, append the dataframe name to each column
FIL_SDS_EMPLOYEE_temp = FIL_SDS_EMPLOYEE.toDF(*["FIL_SDS_EMPLOYEE___" + col for col in FIL_SDS_EMPLOYEE.columns])

EXP_SDS_EMPLOYEE = FIL_SDS_EMPLOYEE_temp.selectExpr(
	"FIL_SDS_EMPLOYEE___sys_row_id as sys_row_id",
	"FIL_SDS_EMPLOYEE___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"FIL_SDS_EMPLOYEE___SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"FIL_SDS_EMPLOYEE___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"FIL_SDS_EMPLOYEE___LOCATION_ID as LOCATION_ID",
	"FIL_SDS_EMPLOYEE___SDS_USER_ID as SDS_USER_ID",
	"FIL_SDS_EMPLOYEE___EMPLOYEE_ID as EMPLOYEE_ID",
	"FIL_SDS_EMPLOYEE___ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME",
	"FIL_SDS_EMPLOYEE___SDS_EMPLOYEE_GROUP_GID as SDS_EMPLOYEE_GROUP_GID",
	"FIL_SDS_EMPLOYEE___SDS_EMPLOYEE_GROUP_NAME as SDS_EMPLOYEE_GROUP_NAME",
	"FIL_SDS_EMPLOYEE___EMPL_FIRST_NAME as EMPL_FIRST_NAME",
	"FIL_SDS_EMPLOYEE___EMPL_LAST_NAME as EMPL_LAST_NAME",
	"FIL_SDS_EMPLOYEE___EMPL_STATUS_CD as EMPL_STATUS_CD",
	"FIL_SDS_EMPLOYEE___EMPL_STATUS_DESC as EMPL_STATUS_DESC",
	"FIL_SDS_EMPLOYEE___BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"FIL_SDS_EMPLOYEE___BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"FIL_SDS_EMPLOYEE___MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"FIL_SDS_EMPLOYEE___EMPL_TERM_DT as EMPL_TERM_DT",
	"FIL_SDS_EMPLOYEE___i_SDS_EMPLOYEE_ID as i_SDS_EMPLOYEE_ID",
	"FIL_SDS_EMPLOYEE___i_SDS_LOCATION_ID as i_SDS_LOCATION_ID",
	"FIL_SDS_EMPLOYEE___i_LOCATION_ID as i_LOCATION_ID",
	"FIL_SDS_EMPLOYEE___i_SDS_USER_ID as i_SDS_USER_ID",
	"FIL_SDS_EMPLOYEE___i_EMPLOYEE_ID as i_EMPLOYEE_ID",
	"FIL_SDS_EMPLOYEE___i_SDS_EMPLOYEE_GROUP_GID as i_SDS_EMPLOYEE_GROUP_GID",
	"FIL_SDS_EMPLOYEE___i_SDS_EMPLOYEE_GROUP_NAME as i_SDS_EMPLOYEE_GROUP_NAME",
	"FIL_SDS_EMPLOYEE___i_SDS_EMPLOYEE_DISPLAY_NAME as i_SDS_EMPLOYEE_DISPLAY_NAME",
	"FIL_SDS_EMPLOYEE___i_EMPLOYEE_FIRST_NAME as i_EMPLOYEE_FIRST_NAME",
	"FIL_SDS_EMPLOYEE___i_EMPLOYEE_LAST_NAME as i_EMPLOYEE_LAST_NAME",
	"FIL_SDS_EMPLOYEE___i_EMPLOYEE_STATUS_CD as i_EMPLOYEE_STATUS_CD",
	"FIL_SDS_EMPLOYEE___i_EMPLOYEE_STATUS_DESC as i_EMPLOYEE_STATUS_DESC",
	"FIL_SDS_EMPLOYEE___i_EMPLOYEE_TERM_DT as i_EMPLOYEE_TERM_DT",
	"CURRENT_TIMESTAMP as UPDATE_TSTMP",
	"IF (FIL_SDS_EMPLOYEE___i_LOAD_TSTMP IS NULL, CURRENT_TIMESTAMP, FIL_SDS_EMPLOYEE___i_LOAD_TSTMP) as LOAD_TSTMP",
	"IF (FIL_SDS_EMPLOYEE___i_SDS_EMPLOYEE_ID IS NULL, 1, 2) as o_UPDATE_VALIDATOR",
	"FIL_SDS_EMPLOYEE___ACTIVE_FLAG as ACTIVE_FLAG",
	"FIL_SDS_EMPLOYEE___MAX_WEIGHT as MAX_WEIGHT",
	"FIL_SDS_EMPLOYEE___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT"
)

# COMMAND ----------
# Processing node UPD_SDS_EMPLOYEE, type UPDATE_STRATEGY 
# COLUMN COUNT: 23

# for each involved DataFrame, append the dataframe name to each column
EXP_SDS_EMPLOYEE_temp = EXP_SDS_EMPLOYEE.toDF(*["EXP_SDS_EMPLOYEE___" + col for col in EXP_SDS_EMPLOYEE.columns])

UPD_SDS_EMPLOYEE = EXP_SDS_EMPLOYEE_temp.selectExpr(
	"EXP_SDS_EMPLOYEE___SDS_SERVICE_RESOURCE_ID as SDS_SERVICE_RESOURCE_ID",
	"EXP_SDS_EMPLOYEE___SDS_SERVICE_RESOURCE_NAME as SDS_SERVICE_RESOURCE_NAME",
	"EXP_SDS_EMPLOYEE___SDS_SERVICE_TERRITORY_ID as SDS_SERVICE_TERRITORY_ID",
	"EXP_SDS_EMPLOYEE___LOCATION_ID as LOCATION_ID",
	"EXP_SDS_EMPLOYEE___SDS_USER_ID as SDS_USER_ID",
	"EXP_SDS_EMPLOYEE___EMPLOYEE_ID as EMPLOYEE_ID",
	"EXP_SDS_EMPLOYEE___ASSOCIATE_DISPLAY_NAME as ASSOCIATE_DISPLAY_NAME",
	"EXP_SDS_EMPLOYEE___SDS_EMPLOYEE_GROUP_GID as SDS_EMPLOYEE_GROUP_GID",
	"EXP_SDS_EMPLOYEE___SDS_EMPLOYEE_GROUP_NAME as SDS_EMPLOYEE_GROUP_NAME",
	"EXP_SDS_EMPLOYEE___EMPL_FIRST_NAME as EMPL_FIRST_NAME",
	"EXP_SDS_EMPLOYEE___EMPL_LAST_NAME as EMPL_LAST_NAME",
	"EXP_SDS_EMPLOYEE___EMPL_STATUS_CD as EMPL_STATUS_CD",
	"EXP_SDS_EMPLOYEE___EMPL_STATUS_DESC as EMPL_STATUS_DESC",
	"EXP_SDS_EMPLOYEE___BLOCK_1_APPOINTMENT_CAPACITY as BLOCK_1_APPOINTMENT_CAPACITY",
	"EXP_SDS_EMPLOYEE___BLOCK_2_APPOINTMENT_CAPACITY as BLOCK_2_APPOINTMENT_CAPACITY",
	"EXP_SDS_EMPLOYEE___MAX_CHECK_IN_PER_HOUR as MAX_CHECK_IN_PER_HOUR",
	"EXP_SDS_EMPLOYEE___EMPL_TERM_DT as EMPL_TERM_DT",
	"EXP_SDS_EMPLOYEE___UPDATE_TSTMP as UPDATE_TSTMP",
	"EXP_SDS_EMPLOYEE___LOAD_TSTMP as LOAD_TSTMP",
	"EXP_SDS_EMPLOYEE___o_UPDATE_VALIDATOR as o_UPDATE_VALIDATOR",
	"EXP_SDS_EMPLOYEE___ACTIVE_FLAG as ACTIVE_FLAG",
	"EXP_SDS_EMPLOYEE___MAX_WEIGHT as MAX_WEIGHT",
	"EXP_SDS_EMPLOYEE___OLD_MAX_WEIGHT as OLD_MAX_WEIGHT")\
	.withColumn('pyspark_data_action', when(col('o_UPDATE_VALIDATOR') ==(lit(1)) , lit(0)).when(col('o_UPDATE_VALIDATOR') ==(lit(2)) , lit(1)))

# COMMAND ----------
# Processing node Shortcut_to_SDS_EMPLOYEE_2, type TARGET 
# COLUMN COUNT: 21


Shortcut_to_SDS_EMPLOYEE_2 = UPD_SDS_EMPLOYEE.selectExpr(
	"CAST(SDS_SERVICE_RESOURCE_ID AS STRING) as SDS_EMPLOYEE_ID",
	"CAST(SDS_SERVICE_TERRITORY_ID AS STRING) as SDS_LOCATION_ID",
	"CAST(LOCATION_ID AS BIGINT) as LOCATION_ID",
	"CAST(SDS_USER_ID AS STRING) as SDS_USER_ID",
	"CAST(EMPLOYEE_ID AS BIGINT) as EMPLOYEE_ID",
	"CAST(SDS_EMPLOYEE_GROUP_GID AS BIGINT) as SDS_EMPLOYEE_GROUP_GID",
	"CAST(SDS_EMPLOYEE_GROUP_NAME AS STRING) as SDS_EMPLOYEE_GROUP_NAME",
	"CAST(ASSOCIATE_DISPLAY_NAME AS STRING) as SDS_EMPLOYEE_DISPLAY_NAME",
	"CAST(EMPL_FIRST_NAME AS STRING) as EMPLOYEE_FIRST_NAME",
	"CAST(EMPL_LAST_NAME AS STRING) as EMPLOYEE_LAST_NAME",
	"CAST(EMPL_STATUS_CD AS STRING) as EMPLOYEE_STATUS_CD",
	"CAST(EMPL_STATUS_DESC AS STRING) as EMPLOYEE_STATUS_DESC",
	"CAST(EMPL_TERM_DT AS DATE) as EMPLOYEE_TERM_DT",
	"CAST(ACTIVE_FLAG AS TINYINT) as SDS_EMPLOYEE_ACTIVE_FLAG",
	"CAST(BLOCK_1_APPOINTMENT_CAPACITY AS BIGINT) as MAX_BLOCK_1_CAPACITY",
	"CAST(BLOCK_2_APPOINTMENT_CAPACITY AS BIGINT) as MAX_BLOCK_2_CAPACITY",
	"CAST(MAX_CHECK_IN_PER_HOUR AS BIGINT) as MAX_CHECK_IN_PER_HOUR",
	"CAST(UPDATE_TSTMP AS TIMESTAMP) as UPDATE_TSTMP",
	"CAST(LOAD_TSTMP AS TIMESTAMP) as LOAD_TSTMP",
	"CAST(MAX_WEIGHT AS DECIMAL(18,3)) as MAX_WEIGHT",
	"CAST(OLD_MAX_WEIGHT AS DECIMAL(18,3)) as OLD_MAX_WEIGHT",
	"UPD_SDS_EMPLOYEE.pyspark_data_action as pyspark_data_action"
)

try:
  primary_key = """source.SDS_EMPLOYEE_ID = target.SDS_EMPLOYEE_ID AND source.SDS_LOCATION_ID = target.SDS_LOCATION_ID"""
  refined_perf_table = f"{legacy}.SDS_EMPLOYEE"
  executeMerge(Shortcut_to_SDS_EMPLOYEE_2, refined_perf_table, primary_key)
  logger.info(f"Merge with {refined_perf_table} completed]")
  logPrevRunDt("SDS_EMPLOYEE", "SDS_EMPLOYEE", "Completed", "N/A", f"{raw}.log_run_details")
except Exception as e:
  logPrevRunDt("SDS_EMPLOYEE", "SDS_EMPLOYEE","Failed",str(e), f"{raw}.log_run_details", )
  raise e
	