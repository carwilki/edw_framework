#Code converted on 2023-06-22 17:50:13
import os
import argparse
from pyspark.sql import *
from pyspark.sql.functions import *
from pyspark.sql.window import Window
from pyspark.sql.types import *
from datetime import datetime
from pyspark.dbutils import DBUtils
from Datalake.utils.genericUtilities import *
from Datalake.utils.configs import *
from Datalake.utils.mergeUtils import *
from Datalake.utils.logger import *
# COMMAND ----------

parser = argparse.ArgumentParser()
spark = SparkSession.getActiveSession()
dbutils = DBUtils(spark)

parser.add_argument('env', type=str, help='Env Variable')
args = parser.parse_args()
env = args.env

if env is None or env == '':
    raise ValueError('env is not set')

refine = getEnvPrefix(env) + 'refine'
raw = getEnvPrefix(env) + 'raw'
legacy = getEnvPrefix(env) + 'legacy'

# Set global variables
starttime = datetime.now() #start timestamp of the script
refined_perf_table = f"{refine}.WM_PUTAWAY_LOCK"
raw_perf_table = f"{raw}.WM_PUTAWAY_LOCK_PRE"
site_profile_table = f"{legacy}.SITE_PROFILE"


# COMMAND ----------
pre_perf_table = f"{raw}.WM_PUTAWAY_LOCK_PRE"
refined_perf_table = f"{refine}.WM_BUSINESS_PARTNER"
site_profile_table = f"{legacy}.SITE_PROFILE"

Prev_Run_Dt=genPrevRunDt(refined_perf_table, refine,raw)
Del_Logic=args.Del_Logic

# COMMAND ----------
# Processing node SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE, type SOURCE 
# COLUMN COUNT: 10

SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE = spark.sql(f"""SELECT
DC_NBR,
LOCN_ID,
LOCK_COUNTER,
CREATED_DTTM,
CREATED_SOURCE_TYPE,
CREATED_SOURCE,
LAST_UPDATED_DTTM,
LAST_UPDATED_SOURCE_TYPE,
LAST_UPDATED_SOURCE,
LOAD_TSTMP
FROM {raw_perf_table}""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node EXPTRANS, type EXPRESSION 
# COLUMN COUNT: 10

# for each involved DataFrame, append the dataframe name to each column
SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE_temp = SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE.toDF(*["SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___" + col for col in SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE.columns])

EXPTRANS = SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE_temp.selectExpr( 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___sys_row_id as sys_row_id", 
	"cast(SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___DC_NBR as int) as DC_NBR_EXP", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___LOCN_ID as LOCN_ID", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___LOCK_COUNTER as LOCK_COUNTER", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___CREATED_DTTM as CREATED_DTTM", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___CREATED_SOURCE_TYPE as CREATED_SOURCE_TYPE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___CREATED_SOURCE as CREATED_SOURCE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___LAST_UPDATED_DTTM as LAST_UPDATED_DTTM", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___LAST_UPDATED_SOURCE_TYPE as LAST_UPDATED_SOURCE_TYPE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___LAST_UPDATED_SOURCE as LAST_UPDATED_SOURCE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK_PRE___LOAD_TSTMP as LOAD_TSTMP" 
)

# COMMAND ----------
# Processing node SQ_Shortcut_to_WM_PUTAWAY_LOCK, type SOURCE 
# COLUMN COUNT: 11

SQ_Shortcut_to_WM_PUTAWAY_LOCK = spark.sql(f"""SELECT
LOCATION_ID,
WM_LOCN_ID,
LOCK_COUNTER,
WM_CREATED_SOURCE_TYPE,
WM_CREATED_SOURCE,
WM_CREATED_TSTMP,
WM_LAST_UPDATED_SOURCE_TYPE,
WM_LAST_UPDATED_SOURCE,
WM_LAST_UPDATED_TSTMP,
DELETE_FLAG,
LOAD_TSTMP
FROM {refined_perf_table}
WHERE {Del_Logic} 1=0 and 
DELETE_FLAG = 0""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node SQ_Shortcut_to_SITE_PROFILE, type SOURCE 
# COLUMN COUNT: 2

SQ_Shortcut_to_SITE_PROFILE = spark.sql(f"""SELECT LOCATION_ID, STORE_NBR FROM {site_profile_table}""").withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node JNR_SITE_PROFILE, type JOINER 
# COLUMN COUNT: 11

JNR_SITE_PROFILE = EXPTRANS.join(SQ_Shortcut_to_SITE_PROFILE,[EXPTRANS.DC_NBR_EXP == SQ_Shortcut_to_SITE_PROFILE.STORE_NBR],'inner')

# COMMAND ----------
# Processing node JNR_WM_PUTAWAY_LOCK, type JOINER . Note: using additional SELECT to rename incoming columns
# COLUMN COUNT: 20

# for each involved DataFrame, append the dataframe name to each column
JNR_SITE_PROFILE_temp = JNR_SITE_PROFILE.toDF(*["JNR_SITE_PROFILE___" + col for col in JNR_SITE_PROFILE.columns])
SQ_Shortcut_to_WM_PUTAWAY_LOCK_temp = SQ_Shortcut_to_WM_PUTAWAY_LOCK.toDF(*["SQ_Shortcut_to_WM_PUTAWAY_LOCK___" + col for col in SQ_Shortcut_to_WM_PUTAWAY_LOCK.columns])

JNR_WM_PUTAWAY_LOCK = SQ_Shortcut_to_WM_PUTAWAY_LOCK_temp.join(JNR_SITE_PROFILE_temp,[SQ_Shortcut_to_WM_PUTAWAY_LOCK_temp.SQ_Shortcut_to_WM_PUTAWAY_LOCK___LOCATION_ID == JNR_SITE_PROFILE_temp.JNR_SITE_PROFILE___LOCATION_ID, SQ_Shortcut_to_WM_PUTAWAY_LOCK_temp.SQ_Shortcut_to_WM_PUTAWAY_LOCK___WM_LOCN_ID == JNR_SITE_PROFILE_temp.JNR_SITE_PROFILE___LOCN_ID],'fullouter').selectExpr( 
	"JNR_SITE_PROFILE___LOCATION_ID as LOCATION_ID", 
	"JNR_SITE_PROFILE___LOCN_ID as LOCN_ID", 
	"JNR_SITE_PROFILE___LOCK_COUNTER as LOCK_COUNTER", 
	"JNR_SITE_PROFILE___CREATED_DTTM as CREATED_DTTM", 
	"JNR_SITE_PROFILE___CREATED_SOURCE_TYPE as CREATED_SOURCE_TYPE", 
	"JNR_SITE_PROFILE___CREATED_SOURCE as CREATED_SOURCE", 
	"JNR_SITE_PROFILE___LAST_UPDATED_DTTM as LAST_UPDATED_DTTM", 
	"JNR_SITE_PROFILE___LAST_UPDATED_SOURCE_TYPE as LAST_UPDATED_SOURCE_TYPE", 
	"JNR_SITE_PROFILE___LAST_UPDATED_SOURCE as LAST_UPDATED_SOURCE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___LOCATION_ID as in_LOCATION_ID", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___WM_LOCN_ID as WM_LOCN_ID", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___LOCK_COUNTER as in_LOCK_COUNTER", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___WM_CREATED_SOURCE_TYPE as WM_CREATED_SOURCE_TYPE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___WM_CREATED_SOURCE as WM_CREATED_SOURCE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___WM_CREATED_TSTMP as WM_CREATED_TSTMP", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___WM_LAST_UPDATED_SOURCE_TYPE as WM_LAST_UPDATED_SOURCE_TYPE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___WM_LAST_UPDATED_SOURCE as WM_LAST_UPDATED_SOURCE", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___WM_LAST_UPDATED_TSTMP as WM_LAST_UPDATED_TSTMP", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___DELETE_FLAG as in_DELETE_FLAG", 
	"SQ_Shortcut_to_WM_PUTAWAY_LOCK___LOAD_TSTMP as in_LOAD_TSTMP")

# COMMAND ----------
# Processing node FIL_UNCHANGED_REC, type FILTER 
# COLUMN COUNT: 20

# for each involved DataFrame, append the dataframe name to each column
JNR_WM_PUTAWAY_LOCK_temp = JNR_WM_PUTAWAY_LOCK.toDF(*["JNR_WM_PUTAWAY_LOCK___" + col for col in JNR_WM_PUTAWAY_LOCK.columns])

FIL_UNCHANGED_REC = JNR_WM_PUTAWAY_LOCK_temp.selectExpr( 
	"JNR_WM_PUTAWAY_LOCK___LOCATION_ID as LOCATION_ID", 
	"JNR_WM_PUTAWAY_LOCK___LOCN_ID as LOCN_ID", 
	"JNR_WM_PUTAWAY_LOCK___LOCK_COUNTER as LOCK_COUNTER", 
	"JNR_WM_PUTAWAY_LOCK___CREATED_DTTM as CREATED_DTTM", 
	"JNR_WM_PUTAWAY_LOCK___CREATED_SOURCE_TYPE as CREATED_SOURCE_TYPE", 
	"JNR_WM_PUTAWAY_LOCK___CREATED_SOURCE as CREATED_SOURCE", 
	"JNR_WM_PUTAWAY_LOCK___LAST_UPDATED_DTTM as LAST_UPDATED_DTTM", 
	"JNR_WM_PUTAWAY_LOCK___LAST_UPDATED_SOURCE_TYPE as LAST_UPDATED_SOURCE_TYPE", 
	"JNR_WM_PUTAWAY_LOCK___LAST_UPDATED_SOURCE as LAST_UPDATED_SOURCE", 
	"JNR_WM_PUTAWAY_LOCK___in_LOCATION_ID as in_LOCATION_ID", 
	"JNR_WM_PUTAWAY_LOCK___WM_LOCN_ID as WM_LOCN_ID", 
	"JNR_WM_PUTAWAY_LOCK___in_LOCK_COUNTER as in_LOCK_COUNTER", 
	"JNR_WM_PUTAWAY_LOCK___WM_CREATED_SOURCE_TYPE as WM_CREATED_SOURCE_TYPE", 
	"JNR_WM_PUTAWAY_LOCK___WM_CREATED_SOURCE as WM_CREATED_SOURCE", 
	"JNR_WM_PUTAWAY_LOCK___WM_CREATED_TSTMP as WM_CREATED_TSTMP", 
	"JNR_WM_PUTAWAY_LOCK___WM_LAST_UPDATED_SOURCE_TYPE as WM_LAST_UPDATED_SOURCE_TYPE", 
	"JNR_WM_PUTAWAY_LOCK___WM_LAST_UPDATED_SOURCE as WM_LAST_UPDATED_SOURCE", 
	"JNR_WM_PUTAWAY_LOCK___WM_LAST_UPDATED_TSTMP as WM_LAST_UPDATED_TSTMP", 
	"JNR_WM_PUTAWAY_LOCK___in_DELETE_FLAG as in_DELETE_FLAG", 
	"JNR_WM_PUTAWAY_LOCK___in_LOAD_TSTMP as in_LOAD_TSTMP").filter(expr("WM_LOCN_ID IS NULL OR LOCN_ID IS NULL OR (NOT WM_LOCN_ID IS NULL AND (COALESCE(CREATED_DTTM, date'1900-01-01') != COALESCE(WM_CREATED_TSTMP, date'1900-01-01')) OR (COALESCE(LAST_UPDATED_DTTM, date'1900-01-01') != COALESCE(WM_LAST_UPDATED_TSTMP, date'1900-01-01')))")).withColumn("sys_row_id", monotonically_increasing_id())

# COMMAND ----------
# Processing node EXP_UPD_VALIDATOR, type EXPRESSION 
# COLUMN COUNT: 24

# for each involved DataFrame, append the dataframe name to each column
FIL_UNCHANGED_REC_temp = FIL_UNCHANGED_REC.toDF(*["FIL_UNCHANGED_REC___" + col for col in FIL_UNCHANGED_REC.columns]) \
    .withColumn("v_CREATED_DTTM", expr("""IF(CREATED_DTTM IS NULL, date'1900-01-01', CREATED_DTTM)""")) \
	.withColumn("v_LAST_UPDATED_DTTM", expr("""IF(LAST_UPDATED_DTTM IS NULL, date'1900-01-01', LAST_UPDATED_DTTM)""")) \
	.withColumn("v_WM_CREATED_TSTMP", expr("""IF(WM_CREATED_TSTMP IS NULL, date'1900-01-01', WM_CREATED_TSTMP)""")) \
	.withColumn("v_WM_LAST_UPDATED_TSTMP", expr("""IF(WM_LAST_UPDATED_TSTMP IS NULL, date'1900-01-01', WM_LAST_UPDATED_TSTMP)"""))
    
EXP_UPD_VALIDATOR = FIL_UNCHANGED_REC_temp.selectExpr( 
	"FIL_UNCHANGED_REC___sys_row_id as sys_row_id", 
	"FIL_UNCHANGED_REC___LOCATION_ID as LOCATION_ID", 
	"FIL_UNCHANGED_REC___LOCN_ID as LOCN_ID", 
	"FIL_UNCHANGED_REC___LOCK_COUNTER as LOCK_COUNTER", 
	"FIL_UNCHANGED_REC___CREATED_DTTM as CREATED_DTTM", 
	"FIL_UNCHANGED_REC___CREATED_SOURCE_TYPE as CREATED_SOURCE_TYPE", 
	"FIL_UNCHANGED_REC___CREATED_SOURCE as CREATED_SOURCE", 
	"FIL_UNCHANGED_REC___LAST_UPDATED_DTTM as LAST_UPDATED_DTTM", 
	"FIL_UNCHANGED_REC___LAST_UPDATED_SOURCE_TYPE as LAST_UPDATED_SOURCE_TYPE", 
	"FIL_UNCHANGED_REC___LAST_UPDATED_SOURCE as LAST_UPDATED_SOURCE", 
	"FIL_UNCHANGED_REC___in_LOCATION_ID as in_LOCATION_ID", 
	"FIL_UNCHANGED_REC___WM_LOCN_ID as WM_LOCN_ID", 
	"FIL_UNCHANGED_REC___in_LOCK_COUNTER as in_LOCK_COUNTER", 
	"FIL_UNCHANGED_REC___WM_CREATED_SOURCE_TYPE as WM_CREATED_SOURCE_TYPE", 
	"FIL_UNCHANGED_REC___WM_CREATED_SOURCE as WM_CREATED_SOURCE", 
	"FIL_UNCHANGED_REC___WM_CREATED_TSTMP as WM_CREATED_TSTMP", 
	"FIL_UNCHANGED_REC___WM_LAST_UPDATED_SOURCE_TYPE as WM_LAST_UPDATED_SOURCE_TYPE", 
	"FIL_UNCHANGED_REC___WM_LAST_UPDATED_SOURCE as WM_LAST_UPDATED_SOURCE", 
	"FIL_UNCHANGED_REC___WM_LAST_UPDATED_TSTMP as WM_LAST_UPDATED_TSTMP", 
	"FIL_UNCHANGED_REC___in_DELETE_FLAG as in_DELETE_FLAG", 
	"FIL_UNCHANGED_REC___in_LOAD_TSTMP as in_LOAD_TSTMP", 
	"IF(FIL_UNCHANGED_REC___LOCN_ID IS NULL AND FIL_UNCHANGED_REC___WM_LOCN_ID IS NOT NULL, 1, 0) as DELETE_FLAG", 
	"CURRENT_TIMESTAMP as UPDATE_TSTMP", 
	"IF(FIL_UNCHANGED_REC___in_LOAD_TSTMP IS NULL, CURRENT_TIMESTAMP, FIL_UNCHANGED_REC___in_LOAD_TSTMP) as LOAD_TSTMP", 
	"IF(FIL_UNCHANGED_REC___LOCN_ID IS NOT NULL AND FIL_UNCHANGED_REC___WM_LOCN_ID IS NULL, 'INSERT', IF(FIL_UNCHANGED_REC___LOCN_ID IS NULL AND FIL_UNCHANGED_REC___WM_LOCN_ID IS NOT NULL AND ( FIL_UNCHANGED_REC___v_WM_CREATED_TSTMP >= DATE_ADD(- 14, {Prev_Run_Dt}) OR FIL_UNCHANGED_REC___v_WM_LAST_UPDATED_TSTMP >= DATE_ADD(- 14, {Prev_Run_Dt}) ), 'DELETE', IF(FIL_UNCHANGED_REC___LOCN_ID IS NOT NULL AND FIL_UNCHANGED_REC___WM_LOCN_ID IS NOT NULL AND ( FIL_UNCHANGED_REC___v_WM_CREATED_TSTMP <> FIL_UNCHANGED_REC___v_CREATED_DTTM OR FIL_UNCHANGED_REC___v_WM_LAST_UPDATED_TSTMP <> FIL_UNCHANGED_REC___v_LAST_UPDATED_DTTM ), 'UPDATE', NULL))) as o_UPD_VALIDATOR" \
)

# COMMAND ----------
# Processing node RTR_DELETE, type ROUTER 
# COLUMN COUNT: 24


# Creating output dataframe for RTR_DELETE, output group DELETE
RTR_DELETE_DELETE = EXP_UPD_VALIDATOR.select(EXP_UPD_VALIDATOR.sys_row_id.alias('sys_row_id'), 
	EXP_UPD_VALIDATOR.LOCATION_ID.alias('LOCATION_ID3'), 
	EXP_UPD_VALIDATOR.LOCN_ID.alias('LOCN_ID3'), 
	EXP_UPD_VALIDATOR.LOCK_COUNTER.alias('LOCK_COUNTER3'), 
	EXP_UPD_VALIDATOR.CREATED_DTTM.alias('CREATED_DTTM3'), 
	EXP_UPD_VALIDATOR.CREATED_SOURCE_TYPE.alias('CREATED_SOURCE_TYPE3'), 
	EXP_UPD_VALIDATOR.CREATED_SOURCE.alias('CREATED_SOURCE3'), 
	EXP_UPD_VALIDATOR.LAST_UPDATED_DTTM.alias('LAST_UPDATED_DTTM3'), 
	EXP_UPD_VALIDATOR.LAST_UPDATED_SOURCE_TYPE.alias('LAST_UPDATED_SOURCE_TYPE3'), 
	EXP_UPD_VALIDATOR.LAST_UPDATED_SOURCE.alias('LAST_UPDATED_SOURCE3'), 
	EXP_UPD_VALIDATOR.in_LOCATION_ID.alias('in_LOCATION_ID3'), 
	EXP_UPD_VALIDATOR.WM_LOCN_ID.alias('WM_LOCN_ID3'), 
	EXP_UPD_VALIDATOR.in_LOCK_COUNTER.alias('in_LOCK_COUNTER3'), 
	EXP_UPD_VALIDATOR.WM_CREATED_SOURCE_TYPE.alias('WM_CREATED_SOURCE_TYPE3'), 
	EXP_UPD_VALIDATOR.WM_CREATED_SOURCE.alias('WM_CREATED_SOURCE3'), 
	EXP_UPD_VALIDATOR.WM_CREATED_TSTMP.alias('WM_CREATED_TSTMP3'), 
	EXP_UPD_VALIDATOR.WM_LAST_UPDATED_SOURCE_TYPE.alias('WM_LAST_UPDATED_SOURCE_TYPE3'), 
	EXP_UPD_VALIDATOR.WM_LAST_UPDATED_SOURCE.alias('WM_LAST_UPDATED_SOURCE3'), 
	EXP_UPD_VALIDATOR.WM_LAST_UPDATED_TSTMP.alias('WM_LAST_UPDATED_TSTMP3'), 
	EXP_UPD_VALIDATOR.in_DELETE_FLAG.alias('in_DELETE_FLAG3'), 
	EXP_UPD_VALIDATOR.in_LOAD_TSTMP.alias('in_LOAD_TSTMP3'), 
	EXP_UPD_VALIDATOR.DELETE_FLAG.alias('DELETE_FLAG3'), 
	EXP_UPD_VALIDATOR.UPDATE_TSTMP.alias('UPDATE_TSTMP3'), 
	EXP_UPD_VALIDATOR.LOAD_TSTMP.alias('LOAD_TSTMP3'), 
	EXP_UPD_VALIDATOR.o_UPD_VALIDATOR.alias('o_UPD_VALIDATOR3')).filter("o_UPD_VALIDATOR = 'DELETE'")

# Creating output dataframe for RTR_DELETE, output group INSERT_UPDATE
RTR_DELETE_INSERT_UPDATE = EXP_UPD_VALIDATOR.select(EXP_UPD_VALIDATOR.sys_row_id.alias('sys_row_id'), 
	EXP_UPD_VALIDATOR.LOCATION_ID.alias('LOCATION_ID1'), 
	EXP_UPD_VALIDATOR.LOCN_ID.alias('LOCN_ID1'), 
	EXP_UPD_VALIDATOR.LOCK_COUNTER.alias('LOCK_COUNTER1'), 
	EXP_UPD_VALIDATOR.CREATED_DTTM.alias('CREATED_DTTM1'), 
	EXP_UPD_VALIDATOR.CREATED_SOURCE_TYPE.alias('CREATED_SOURCE_TYPE1'), 
	EXP_UPD_VALIDATOR.CREATED_SOURCE.alias('CREATED_SOURCE1'), 
	EXP_UPD_VALIDATOR.LAST_UPDATED_DTTM.alias('LAST_UPDATED_DTTM1'), 
	EXP_UPD_VALIDATOR.LAST_UPDATED_SOURCE_TYPE.alias('LAST_UPDATED_SOURCE_TYPE1'), 
	EXP_UPD_VALIDATOR.LAST_UPDATED_SOURCE.alias('LAST_UPDATED_SOURCE1'), 
	EXP_UPD_VALIDATOR.in_LOCATION_ID.alias('in_LOCATION_ID1'), 
	EXP_UPD_VALIDATOR.WM_LOCN_ID.alias('WM_LOCN_ID1'), 
	EXP_UPD_VALIDATOR.in_LOCK_COUNTER.alias('in_LOCK_COUNTER1'), 
	EXP_UPD_VALIDATOR.WM_CREATED_SOURCE_TYPE.alias('WM_CREATED_SOURCE_TYPE1'), 
	EXP_UPD_VALIDATOR.WM_CREATED_SOURCE.alias('WM_CREATED_SOURCE1'), 
	EXP_UPD_VALIDATOR.WM_CREATED_TSTMP.alias('WM_CREATED_TSTMP1'), 
	EXP_UPD_VALIDATOR.WM_LAST_UPDATED_SOURCE_TYPE.alias('WM_LAST_UPDATED_SOURCE_TYPE1'), 
	EXP_UPD_VALIDATOR.WM_LAST_UPDATED_SOURCE.alias('WM_LAST_UPDATED_SOURCE1'), 
	EXP_UPD_VALIDATOR.WM_LAST_UPDATED_TSTMP.alias('WM_LAST_UPDATED_TSTMP1'), 
	EXP_UPD_VALIDATOR.in_DELETE_FLAG.alias('in_DELETE_FLAG1'), 
	EXP_UPD_VALIDATOR.in_LOAD_TSTMP.alias('in_LOAD_TSTMP1'), 
	EXP_UPD_VALIDATOR.DELETE_FLAG.alias('DELETE_FLAG1'), 
	EXP_UPD_VALIDATOR.UPDATE_TSTMP.alias('UPDATE_TSTMP1'), 
	EXP_UPD_VALIDATOR.LOAD_TSTMP.alias('LOAD_TSTMP1'), 
	EXP_UPD_VALIDATOR.o_UPD_VALIDATOR.alias('o_UPD_VALIDATOR1')).filter("o_UPD_VALIDATOR = 'INSERT' OR o_UPD_VALIDATOR = 'UPDATE'")


# COMMAND ----------
# Processing node UPD_INS_UPD, type UPDATE_STRATEGY 
# COLUMN COUNT: 13

# for each involved DataFrame, append the dataframe name to each column
RTR_DELETE_INSERT_UPDATE_temp = RTR_DELETE_INSERT_UPDATE.toDF(*["RTR_DELETE_INSERT_UPDATE___" + col for col in RTR_DELETE_INSERT_UPDATE.columns])

UPD_INS_UPD = RTR_DELETE_INSERT_UPDATE_temp.selectExpr( 
	"RTR_DELETE_INSERT_UPDATE___LOCATION_ID1 as LOCATION_ID1", 
	"RTR_DELETE_INSERT_UPDATE___LOCN_ID1 as LOCN_ID1", 
	"RTR_DELETE_INSERT_UPDATE___LOCK_COUNTER1 as LOCK_COUNTER1", 
	"RTR_DELETE_INSERT_UPDATE___CREATED_SOURCE_TYPE1 as CREATED_SOURCE_TYPE1", 
	"RTR_DELETE_INSERT_UPDATE___CREATED_SOURCE1 as CREATED_SOURCE1", 
	"RTR_DELETE_INSERT_UPDATE___CREATED_DTTM1 as CREATED_DTTM1", 
	"RTR_DELETE_INSERT_UPDATE___LAST_UPDATED_SOURCE_TYPE1 as LAST_UPDATED_SOURCE_TYPE1", 
	"RTR_DELETE_INSERT_UPDATE___LAST_UPDATED_SOURCE1 as LAST_UPDATED_SOURCE1", 
	"RTR_DELETE_INSERT_UPDATE___LAST_UPDATED_DTTM1 as LAST_UPDATED_DTTM1", 
	"RTR_DELETE_INSERT_UPDATE___DELETE_FLAG1 as DELETE_FLAG1", 
	"RTR_DELETE_INSERT_UPDATE___UPDATE_TSTMP1 as UPDATE_TSTMP1", 
	"RTR_DELETE_INSERT_UPDATE___LOAD_TSTMP1 as LOAD_TSTMP1", 
	"RTR_DELETE_INSERT_UPDATE___o_UPD_VALIDATOR1 as o_UPD_VALIDATOR1"
).withColumn('pyspark_data_action', when(RTR_DELETE_INSERT_UPDATE.o_UPD_VALIDATOR1 ==(lit('INSERT')),lit(0)).when(RTR_DELETE_INSERT_UPDATE.o_UPD_VALIDATOR1 ==(lit('UPDATE')),lit(1)))

# COMMAND ----------
# Processing node UPD_DELETE, type UPDATE_STRATEGY 
# COLUMN COUNT: 12

# for each involved DataFrame, append the dataframe name to each column
RTR_DELETE_DELETE_temp = RTR_DELETE_DELETE.toDF(*["RTR_DELETE_DELETE___" + col for col in RTR_DELETE_DELETE.columns])

UPD_DELETE = RTR_DELETE_DELETE_temp.selectExpr( 
	"RTR_DELETE_DELETE___in_LOCATION_ID3 as in_LOCATION_ID3", 
	"RTR_DELETE_DELETE___WM_LOCN_ID3 as WM_LOCN_ID3", 
	"RTR_DELETE_DELETE___in_LOCK_COUNTER3 as in_LOCK_COUNTER3", 
	"RTR_DELETE_DELETE___WM_CREATED_SOURCE_TYPE3 as WM_CREATED_SOURCE_TYPE3", 
	"RTR_DELETE_DELETE___WM_CREATED_SOURCE3 as WM_CREATED_SOURCE3", 
	"RTR_DELETE_DELETE___WM_CREATED_TSTMP3 as WM_CREATED_TSTMP3", 
	"RTR_DELETE_DELETE___WM_LAST_UPDATED_SOURCE_TYPE3 as WM_LAST_UPDATED_SOURCE_TYPE3", 
	"RTR_DELETE_DELETE___WM_LAST_UPDATED_SOURCE3 as WM_LAST_UPDATED_SOURCE3", 
	"RTR_DELETE_DELETE___WM_LAST_UPDATED_TSTMP3 as WM_LAST_UPDATED_TSTMP3", 
	"RTR_DELETE_DELETE___DELETE_FLAG3 as DELETE_FLAG3", 
	"RTR_DELETE_DELETE___UPDATE_TSTMP3 as UPDATE_TSTMP3", 
	"RTR_DELETE_DELETE___LOAD_TSTMP3 as LOAD_TSTMP3"
).withColumn('pyspark_data_action', lit(1))

# COMMAND ----------
# Processing node Shortcut_to_WM_PUTAWAY_LOCK1, type TARGET 
# COLUMN COUNT: 12


Shortcut_to_WM_PUTAWAY_LOCK1 = UPD_INS_UPD.selectExpr( 
	"CAST(LOCATION_ID1 AS BIGINT) as LOCATION_ID", 
	"CAST(LOCN_ID1 AS STRING) as WM_LOCN_ID", 
	"CAST(LOCK_COUNTER1 AS BIGINT) as LOCK_COUNTER", 
	"CAST(CREATED_SOURCE_TYPE1 AS BIGINT) as WM_CREATED_SOURCE_TYPE", 
	"CAST(CREATED_SOURCE1 AS STRING) as WM_CREATED_SOURCE", 
	"CAST(CREATED_DTTM1 AS TIMESTAMP) as WM_CREATED_TSTMP", 
	"CAST(LAST_UPDATED_SOURCE_TYPE1 AS BIGINT) as WM_LAST_UPDATED_SOURCE_TYPE", 
	"CAST(LAST_UPDATED_SOURCE1 AS STRING) as WM_LAST_UPDATED_SOURCE", 
	"CAST(LAST_UPDATED_DTTM1 AS TIMESTAMP) as WM_LAST_UPDATED_TSTMP", 
	"CAST(DELETE_FLAG1 AS BIGINT) as DELETE_FLAG", 
	"CAST(UPDATE_TSTMP1 AS TIMESTAMP) as UPDATE_TSTMP", 
	"CAST(LOAD_TSTMP1 AS TIMESTAMP) as LOAD_TSTMP" , 
    "pyspark_data_action"
)

try:
  primary_key = """source.LOCATION_ID = target.LOCATION_ID AND source.WM_LOCN_ID = target.WM_LOCN_ID"""
  # refined_perf_table = "WM_PUTAWAY_LOCK"
  executeMerge(Shortcut_to_WM_PUTAWAY_LOCK1, refined_perf_table, primary_key)
  logger.info(f"Merge with {refined_perf_table} completed]")
  logPrevRunDt("WM_PUTAWAY_LOCK", "WM_PUTAWAY_LOCK", "Completed", "N/A", f"{raw}.log_run_details")
except Exception as e:
  logPrevRunDt("WM_PUTAWAY_LOCK", "WM_PUTAWAY_LOCK","Failed",str(e), f"{raw}.log_run_details", )
  raise e
	


# COMMAND ----------
# Processing node Shortcut_to_WM_PUTAWAY_LOCK2, type TARGET 
# COLUMN COUNT: 12


# Shortcut_to_WM_PUTAWAY_LOCK2 = UPD_DELETE.selectExpr( 
# 	"CAST(in_LOCATION_ID3 AS BIGINT) as LOCATION_ID", 
# 	"CAST(WM_LOCN_ID3 AS STRING) as WM_LOCN_ID", 
# 	"CAST(NULL AS BIGINT) as LOCK_COUNTER", 
# 	"CAST(NULL AS BIGINT) as WM_CREATED_SOURCE_TYPE", 
# 	"CAST(NULL AS STRING) as WM_CREATED_SOURCE", 
# 	"CAST(NULL AS TIMESTAMP) as WM_CREATED_TSTMP", 
# 	"CAST(NULL AS BIGINT) as WM_LAST_UPDATED_SOURCE_TYPE", 
# 	"CAST(NULL AS STRING) as WM_LAST_UPDATED_SOURCE", 
# 	"CAST(NULL AS TIMESTAMP) as WM_LAST_UPDATED_TSTMP", 
# 	"CAST(DELETE_FLAG3 AS BIGINT) as DELETE_FLAG", 
# 	"CAST(UPDATE_TSTMP3 AS TIMESTAMP) as UPDATE_TSTMP", 
# 	"CAST(NULL AS TIMESTAMP) as LOAD_TSTMP" 
# )
# Shortcut_to_WM_PUTAWAY_LOCK2.write.saveAsTable(f'{raw}.WM_PUTAWAY_LOCK')